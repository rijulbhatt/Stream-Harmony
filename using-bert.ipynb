{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9669069,"sourceType":"datasetVersion","datasetId":5908442}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:15:13.869610Z","iopub.execute_input":"2024-10-19T18:15:13.870285Z","iopub.status.idle":"2024-10-19T18:15:13.886709Z","shell.execute_reply.started":"2024-10-19T18:15:13.870247Z","shell.execute_reply":"2024-10-19T18:15:13.885829Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/comments-data/train.csv\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Using BERT ","metadata":{}},{"cell_type":"markdown","source":"### Loading Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:15:13.888574Z","iopub.execute_input":"2024-10-19T18:15:13.889241Z","iopub.status.idle":"2024-10-19T18:15:13.893619Z","shell.execute_reply.started":"2024-10-19T18:15:13.889196Z","shell.execute_reply":"2024-10-19T18:15:13.892640Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### Load Data Set","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/comments-data/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:15:13.894707Z","iopub.execute_input":"2024-10-19T18:15:13.894993Z","iopub.status.idle":"2024-10-19T18:15:14.814820Z","shell.execute_reply.started":"2024-10-19T18:15:13.894962Z","shell.execute_reply":"2024-10-19T18:15:14.813967Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### Splitting into train and test data","metadata":{}},{"cell_type":"code","source":"train_data = df.drop(columns = ['id'])\nX = train_data['comment_text'].to_list() # to_list becasue we want tokensize \ny = train_data.drop(columns = 'comment_text').values # returns a 2 D array each row is a row of labels each column represents a label\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:15:14.817478Z","iopub.execute_input":"2024-10-19T18:15:14.818171Z","iopub.status.idle":"2024-10-19T18:15:14.893125Z","shell.execute_reply.started":"2024-10-19T18:15:14.818118Z","shell.execute_reply":"2024-10-19T18:15:14.892364Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### Tokenizing input data","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndef tokenize_data(texts, tokenizer, max_length=128):\n    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\", max_length=max_length)\n    \ntrain_encodings = tokenize_data(train_X, tokenizer)\ntest_encodings = tokenize_data(test_X, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:15:14.894415Z","iopub.execute_input":"2024-10-19T18:15:14.894794Z","iopub.status.idle":"2024-10-19T18:22:25.205069Z","shell.execute_reply.started":"2024-10-19T18:15:14.894758Z","shell.execute_reply":"2024-10-19T18:22:25.203992Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_encodings['input_ids']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:26:00.328381Z","iopub.execute_input":"2024-10-19T18:26:00.328774Z","iopub.status.idle":"2024-10-19T18:26:00.336306Z","shell.execute_reply.started":"2024-10-19T18:26:00.328737Z","shell.execute_reply":"2024-10-19T18:26:00.335271Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(127656, 128), dtype=int32, numpy=\narray([[  101, 13055, 26568, ...,     0,     0,     0],\n       [  101,  1010,  1023, ...,     0,     0,     0],\n       [  101,  1000,  1996, ...,  1006,  1037,   102],\n       ...,\n       [  101,  1045,  2180, ...,     0,     0,     0],\n       [  101,  1000,  2329, ...,     0,     0,     0],\n       [  101,  2017,  2024, ...,     0,     0,     0]], dtype=int32)>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"### Load and Compile Pretrained BERT Model","metadata":{}},{"cell_type":"code","source":"bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6) \noptimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\nloss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\nbert_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:22:25.207488Z","iopub.execute_input":"2024-10-19T18:22:25.207887Z","iopub.status.idle":"2024-10-19T18:22:28.985246Z","shell.execute_reply.started":"2024-10-19T18:22:25.207844Z","shell.execute_reply":"2024-10-19T18:22:28.984303Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22603dd077a947c3a36332affd0975ed"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Train the Model","metadata":{}},{"cell_type":"code","source":"bert_model.fit(train_encodings['input_ids'], train_y, epochs=3, batch_size=16, validation_data=(test_encodings['input_ids'], test_y))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:26:40.778927Z","iopub.execute_input":"2024-10-19T18:26:40.779691Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\nWARNING: AutoGraph could not transform <function infer_framework at 0x7a90f9a01fc0> and will run it as-is.\nCause: for/else statement not yet supported\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1729362482.022773      78 service.cc:145] XLA service 0x7a8c38535cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1729362482.022823      78 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1729362482.022827      78 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1729362482.199776      78 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"1458/7979 [====>.........................] - ETA: 44:10 - loss: 0.0718 - accuracy: 0.9818","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.save('bert.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Make Predictions","metadata":{}},{"cell_type":"code","source":"predictions = bert_model.predict(test_encodings['input_ids'])\nbinary_predictions = (tf.nn.sigmoid(predictions.logits).numpy() > 0.5).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T18:22:29.043402Z","iopub.status.idle":"2024-10-19T18:22:29.043916Z","shell.execute_reply.started":"2024-10-19T18:22:29.043665Z","shell.execute_reply":"2024-10-19T18:22:29.043690Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Evaluation ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision,Recall,CategoricalAccuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}